Command Line Args: Namespace(config_file='configs/fsod/pretraining-pvtv2-retinanet.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='auto', opts=['--', 'SOLVER.IMS_PER_BATCH', '1', 'SOLVER.ACCUMULATION_STEPS', '8'], additional_configs=['configs/fsod/dota.yaml'])
[06/18 16:02:05 detectron2]: Rank of current process: 0. World size: 1
[06/18 16:02:06 detectron2]: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]
numpy                            1.26.4
detectron2                       0.6 @/home/gonem/.conda/envs/fct/lib/python3.11/site-packages/detectron2
Compiler                         GCC 13.2
CUDA compiler                    CUDA 12.3
detectron2 arch flags            8.9
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.1+cu121 @/home/gonem/.conda/envs/fct/lib/python3.11/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA GeForce RTX 4070 (arch=8.9)
Driver version                   550.54.14
CUDA_HOME                        /opt/cuda
Pillow                           10.2.0
torchvision                      0.18.1+cu121 @/home/gonem/.conda/envs/fct/lib/python3.11/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              Not found
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/18 16:02:06 detectron2]: Command line arguments: Namespace(config_file='configs/fsod/pretraining-pvtv2-retinanet.yaml', resume=True, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='auto', opts=['SOLVER.IMS_PER_BATCH', '1', 'SOLVER.ACCUMULATION_STEPS', '8'], additional_configs=['configs/fsod/dota.yaml'])
[06/18 16:02:06 detectron2]: Contents of args.config_file=configs/fsod/pretraining-pvtv2-retinanet.yaml:
[38;5;204mRESUME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrue[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./weights/pvt_v2_b2_li.pth[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFalse[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbuild_retinanet_pvtv2_fpn_backbone[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mPVT[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mpvt3[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mpvt4[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m'[39m[38;5;186mpvt3[39m[38;5;186m'[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186mpvt4[39m[38;5;186m'[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mp5[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mp6[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;186m"[39m[38;5;186mp5[39m[38;5;186m"[39m[38;5;15m,[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mp6[39m[38;5;186m"[39m[38;5;15m][39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mStandardRPNHead[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mPVT4BoxHead[39m[38;5;186m"[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0002[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m(85000,[39m[38;5;141m [39m[38;5;141m100000)[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m110000[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20000[39m
[38;5;15m  [39m[38;5;204mACCUMULATION_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20000[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m

[06/18 16:02:06 detectron2]: Running with full config:
[38;5;204mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;204mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m  [39m[38;5;204mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m  [39m[38;5;204mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mTrainingSampler[39m
[38;5;204mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mSEEDS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mdota_2014_val2[39m
[38;5;15m  [39m[38;5;204mTEST_KEEPCLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mall[39m
[38;5;15m  [39m[38;5;204mTEST_SHOTS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30[39m
[38;5;15m  [39m[38;5;204mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mdota_2014_train_nonvoc_with_small[39m
[38;5;204mDATA_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./datasets/data/dota_dataset[39m
[38;5;204mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mHACK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;204mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mrelative_range[39m
[38;5;15m  [39m[38;5;204mFORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mBGR[39m
[38;5;15m  [39m[38;5;204mFS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFEW_SHOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSUPPORT_EXCLUDE_QUERY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mSUPPORT_SHOT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mSUPPORT_WAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m  [39m[38;5;204mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpolygon[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1333[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m640[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m672[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m704[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m736[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m768[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m  [39m[38;5;204mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mchoice[39m
[38;5;15m  [39m[38;5;204mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mhorizontal[39m
[38;5;204mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-90[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m90[39m
[38;5;15m    [39m[38;5;204mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mDefaultAnchorGenerator[39m
[38;5;15m    [39m[38;5;204mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m32[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m  [39m[38;5;204mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mbuild_retinanet_pvtv2_fpn_backbone[39m
[38;5;15m    [39m[38;5;204mONLY_TRAIN_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mTRAIN_BRANCH_EMBED[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mTYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mpvt_v2_b2_li[39m
[38;5;15m  [39m[38;5;204mDEVICE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mcuda[39m
[38;5;15m  [39m[38;5;204mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msum[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mpvt3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mpvt4[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m  [39m[38;5;204mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGeneralizedRCNN[39m
[38;5;15m  [39m[38;5;204mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m      [39m[38;5;204mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m      [39m[38;5;204mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4096[39m
[38;5;15m    [39m[38;5;204mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m103.53[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m116.28[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m123.675[39m
[38;5;15m  [39m[38;5;204mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.375[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m57.12[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m58.395[39m
[38;5;15m  [39m[38;5;204mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mRPN[39m
[38;5;15m  [39m[38;5;204mPVT[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mATTN_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mDEPTHS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m    [39m[38;5;204mDROP_PATH_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mDROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mEMBED_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m320[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mGLOBAL_POOL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mavg[39m
[38;5;15m    [39m[38;5;204mLINEAR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMLP_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mNORM_LAYER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mLN[39m
[38;5;15m    [39m[38;5;204mNUM_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mpvt3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mpvt4[39m
[38;5;15m    [39m[38;5;204mPROJ_DROP_RATE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mQKV_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSR_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mFrozenBN[39m
[38;5;15m    [39m[38;5;204mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mpvt4[39m
[38;5;15m    [39m[38;5;204mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m    [39m[38;5;204mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m64[39m
[38;5;15m  [39m[38;5;204mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp7[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m80[39m
[38;5;15m    [39m[38;5;204mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.01[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m    [39m[38;5;204mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m5.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m20.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m10.0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m30.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m      [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m15.0[39m
[38;5;15m    [39m[38;5;204mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.6[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m  [39m[38;5;204mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1024[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m50[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mPVT4BoxHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m    [39m[38;5;204mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mFREEZE_ROI_FEATURE_EXTRACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardROIHeads[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m18[39m
[38;5;15m    [39m[38;5;204mONLY_TRAIN_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.25[39m
[38;5;15m    [39m[38;5;204mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.05[39m
[38;5;15m  [39m[38;5;204mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m512[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mKRCNNConvDeconvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m17[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mMaskRCNNConvUpsampleHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;204mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m14[39m
[38;5;15m    [39m[38;5;204mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;204mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mROIAlignV2[39m
[38;5;15m  [39m[38;5;204mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m256[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141msmooth_l1[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;204mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;204mFREEZE_RPN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mStandardRPNHead[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp6[39m
[38;5;15m    [39m[38;5;204mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m    [39m[38;5;204mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.7[39m
[38;5;15m    [39m[38;5;204mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.5[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;204mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m6000[39m
[38;5;15m    [39m[38;5;204mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4[39m
[38;5;15m    [39m[38;5;204mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m128[39m
[38;5;15m    [39m[38;5;204mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m255[39m
[38;5;15m    [39m[38;5;204mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp2[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp3[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp4[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141mp5[39m
[38;5;15m    [39m[38;5;204mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mSemSegFPNHead[39m
[38;5;15m    [39m[38;5;204mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mGN[39m
[38;5;15m    [39m[38;5;204mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m54[39m
[38;5;15m  [39m[38;5;204mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./weights/pvt_v2_b2_li.pth[39m
[38;5;204mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m./output/dota/build_retinanet_pvtv2_fpn_backbone/pretraining/[39m
[38;5;204mRESUME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;204mSEED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m-1[39m
[38;5;204mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mACCUMULATION_STEPS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m8[39m
[38;5;15m  [39m[38;5;204mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0002[39m
[38;5;15m  [39m[38;5;204mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;15m  [39m[38;5;204mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20000[39m
[38;5;15m  [39m[38;5;204mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mvalue[39m
[38;5;15m    [39m[38;5;204mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2.0[39m
[38;5;15m  [39m[38;5;204mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15m  [39m[38;5;204mHEAD_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1.0[39m
[38;5;15m  [39m[38;5;204mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1[39m
[38;5;15m  [39m[38;5;204mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mWarmupMultiStepLR[39m
[38;5;15m  [39m[38;5;204mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m110000[39m
[38;5;15m  [39m[38;5;204mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.9[39m
[38;5;15m  [39m[38;5;204mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m3[39m
[38;5;15m  [39m[38;5;204mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m
[38;5;15m  [39m[38;5;204mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m  [39m[38;5;204mSOLVER_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141madamw[39m
[38;5;15m  [39m[38;5;204mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m85000[39m
[38;5;15m  [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m100000[39m
[38;5;15m  [39m[38;5;204mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.001[39m
[38;5;15m  [39m[38;5;204mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m  [39m[38;5;204mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mlinear[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0001[39m
[38;5;15m  [39m[38;5;204mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.0[39m
[38;5;204mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;204mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mFLIP[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mtrue[39m
[38;5;15m    [39m[38;5;204mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m4000[39m
[38;5;15m    [39m[38;5;204mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m400[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m500[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m600[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m700[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m800[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m900[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1000[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1100[39m
[38;5;15m    [39m[38;5;15m-[39m[38;5;15m [39m[38;5;141m1200[39m
[38;5;15m  [39m[38;5;204mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m100[39m
[38;5;15m  [39m[38;5;204mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m20000[39m
[38;5;15m  [39m[38;5;204mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m[[39m[38;5;15m][39m
[38;5;15m  [39m[38;5;204mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;204mENABLED[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141mfalse[39m
[38;5;15m    [39m[38;5;204mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m200[39m
[38;5;204mVERSION[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m2[39m
[38;5;204mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0[39m

[06/18 16:02:06 detectron2]: Full config saved to ./output/dota/build_retinanet_pvtv2_fpn_backbone/pretraining/config.yaml
[06/18 16:02:06 d2.utils.env]: Using a generated random seed 7213360
[06/18 16:02:06 d2.engine.defaults]: Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7(
      (p6): Conv2d(320, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): PyramidVisionTransformerV2(
      (patch_embed): OverlapPatchEmbed(
        (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (stages): Sequential(
        (0): PyramidVisionTransformerStage(
          (blocks): ModuleList(
            (0): Block(
              (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=64, out_features=64, bias=True)
                (kv): Linear(in_features=64, out_features=128, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): Identity()
              (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=64, out_features=512, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): Identity()
            )
            (1): Block(
              (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=64, out_features=64, bias=True)
                (kv): Linear(in_features=64, out_features=128, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.007)
              (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=64, out_features=512, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.007)
            )
            (2): Block(
              (norm1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=64, out_features=64, bias=True)
                (kv): Linear(in_features=64, out_features=128, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=64, out_features=64, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.013)
              (norm2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=64, out_features=512, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=512, out_features=64, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.013)
            )
          )
          (norm): LayerNorm((64,), eps=1e-06, elementwise_affine=True)
        )
        (1): PyramidVisionTransformerStage(
          (downsample): OverlapPatchEmbed(
            (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (blocks): ModuleList(
            (0): Block(
              (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=128, out_features=128, bias=True)
                (kv): Linear(in_features=128, out_features=256, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.020)
              (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=128, out_features=1024, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.020)
            )
            (1): Block(
              (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=128, out_features=128, bias=True)
                (kv): Linear(in_features=128, out_features=256, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.027)
              (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=128, out_features=1024, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.027)
            )
            (2): Block(
              (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=128, out_features=128, bias=True)
                (kv): Linear(in_features=128, out_features=256, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.033)
              (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=128, out_features=1024, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.033)
            )
            (3): Block(
              (norm1): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=128, out_features=128, bias=True)
                (kv): Linear(in_features=128, out_features=256, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=128, out_features=128, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.040)
              (norm2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=128, out_features=1024, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1024, out_features=128, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.040)
            )
          )
          (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)
        )
        (2): PyramidVisionTransformerStage(
          (downsample): OverlapPatchEmbed(
            (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
            (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
          )
          (blocks): ModuleList(
            (0): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.047)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.047)
            )
            (1): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.053)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.053)
            )
            (2): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.060)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.060)
            )
            (3): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.067)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.067)
            )
            (4): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.073)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.073)
            )
            (5): Block(
              (norm1): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (attn): Attention(
                (q): Linear(in_features=320, out_features=320, bias=True)
                (kv): Linear(in_features=320, out_features=640, bias=True)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=320, out_features=320, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
                (pool): AdaptiveAvgPool2d(output_size=7)
                (sr): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))
                (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
                (act): GELU(approximate='none')
              )
              (drop_path1): DropPath(drop_prob=0.080)
              (norm2): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
              (mlp): MlpWithDepthwiseConv(
                (fc1): Linear(in_features=320, out_features=1280, bias=True)
                (relu): ReLU()
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1280, out_features=320, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (drop_path2): DropPath(drop_prob=0.080)
            )
          )
          (norm): LayerNorm((320,), eps=1e-06, elementwise_affine=True)
        )
      )
      (head_drop): Dropout(p=0.0, inplace=False)
      (head): Identity()
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.015625, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): PVT4BoxHead(
      (stage): PyramidVisionTransformerStage(
        (downsample): OverlapPatchEmbed(
          (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
        (blocks): ModuleList(
          (0): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (pool): AdaptiveAvgPool2d(output_size=7)
              (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
            (drop_path1): DropPath(drop_prob=0.087)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): MlpWithDepthwiseConv(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU()
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path2): DropPath(drop_prob=0.087)
          )
          (1): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (pool): AdaptiveAvgPool2d(output_size=7)
              (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
            (drop_path1): DropPath(drop_prob=0.093)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): MlpWithDepthwiseConv(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU()
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path2): DropPath(drop_prob=0.093)
          )
          (2): Block(
            (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (attn): Attention(
              (q): Linear(in_features=512, out_features=512, bias=True)
              (kv): Linear(in_features=512, out_features=1024, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=512, out_features=512, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (pool): AdaptiveAvgPool2d(output_size=7)
              (sr): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (act): GELU(approximate='none')
            )
            (drop_path1): DropPath(drop_prob=0.100)
            (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): MlpWithDepthwiseConv(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (relu): ReLU()
              (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path2): DropPath(drop_prob=0.100)
          )
        )
        (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
      )
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=25088, out_features=19, bias=True)
      (bbox_pred): Linear(in_features=25088, out_features=72, bias=True)
    )
  )
)
['backbone.fpn_lateral3.weight', 'backbone.fpn_lateral3.bias', 'backbone.fpn_output3.weight', 'backbone.fpn_output3.bias', 'backbone.fpn_lateral4.weight', 'backbone.fpn_lateral4.bias', 'backbone.fpn_output4.weight', 'backbone.fpn_output4.bias', 'backbone.top_block.p6.weight', 'backbone.top_block.p6.bias', 'backbone.top_block.p7.weight', 'backbone.top_block.p7.bias', 'backbone.bottom_up.stages.1.downsample.proj.weight', 'backbone.bottom_up.stages.1.downsample.proj.bias', 'backbone.bottom_up.stages.1.downsample.norm.weight', 'backbone.bottom_up.stages.1.downsample.norm.bias', 'backbone.bottom_up.stages.1.blocks.0.norm1.weight', 'backbone.bottom_up.stages.1.blocks.0.norm1.bias', 'backbone.bottom_up.stages.1.blocks.0.attn.q.weight', 'backbone.bottom_up.stages.1.blocks.0.attn.q.bias', 'backbone.bottom_up.stages.1.blocks.0.attn.kv.weight', 'backbone.bottom_up.stages.1.blocks.0.attn.kv.bias', 'backbone.bottom_up.stages.1.blocks.0.attn.proj.weight', 'backbone.bottom_up.stages.1.blocks.0.attn.proj.bias', 'backbone.bottom_up.stages.1.blocks.0.attn.sr.weight', 'backbone.bottom_up.stages.1.blocks.0.attn.sr.bias', 'backbone.bottom_up.stages.1.blocks.0.attn.norm.weight', 'backbone.bottom_up.stages.1.blocks.0.attn.norm.bias', 'backbone.bottom_up.stages.1.blocks.0.norm2.weight', 'backbone.bottom_up.stages.1.blocks.0.norm2.bias', 'backbone.bottom_up.stages.1.blocks.0.mlp.fc1.weight', 'backbone.bottom_up.stages.1.blocks.0.mlp.fc1.bias', 'backbone.bottom_up.stages.1.blocks.0.mlp.dwconv.weight', 'backbone.bottom_up.stages.1.blocks.0.mlp.dwconv.bias', 'backbone.bottom_up.stages.1.blocks.0.mlp.fc2.weight', 'backbone.bottom_up.stages.1.blocks.0.mlp.fc2.bias', 'backbone.bottom_up.stages.1.blocks.1.norm1.weight', 'backbone.bottom_up.stages.1.blocks.1.norm1.bias', 'backbone.bottom_up.stages.1.blocks.1.attn.q.weight', 'backbone.bottom_up.stages.1.blocks.1.attn.q.bias', 'backbone.bottom_up.stages.1.blocks.1.attn.kv.weight', 'backbone.bottom_up.stages.1.blocks.1.attn.kv.bias', 'backbone.bottom_up.stages.1.blocks.1.attn.proj.weight', 'backbone.bottom_up.stages.1.blocks.1.attn.proj.bias', 'backbone.bottom_up.stages.1.blocks.1.attn.sr.weight', 'backbone.bottom_up.stages.1.blocks.1.attn.sr.bias', 'backbone.bottom_up.stages.1.blocks.1.attn.norm.weight', 'backbone.bottom_up.stages.1.blocks.1.attn.norm.bias', 'backbone.bottom_up.stages.1.blocks.1.norm2.weight', 'backbone.bottom_up.stages.1.blocks.1.norm2.bias', 'backbone.bottom_up.stages.1.blocks.1.mlp.fc1.weight', 'backbone.bottom_up.stages.1.blocks.1.mlp.fc1.bias', 'backbone.bottom_up.stages.1.blocks.1.mlp.dwconv.weight', 'backbone.bottom_up.stages.1.blocks.1.mlp.dwconv.bias', 'backbone.bottom_up.stages.1.blocks.1.mlp.fc2.weight', 'backbone.bottom_up.stages.1.blocks.1.mlp.fc2.bias', 'backbone.bottom_up.stages.1.blocks.2.norm1.weight', 'backbone.bottom_up.stages.1.blocks.2.norm1.bias', 'backbone.bottom_up.stages.1.blocks.2.attn.q.weight', 'backbone.bottom_up.stages.1.blocks.2.attn.q.bias', 'backbone.bottom_up.stages.1.blocks.2.attn.kv.weight', 'backbone.bottom_up.stages.1.blocks.2.attn.kv.bias', 'backbone.bottom_up.stages.1.blocks.2.attn.proj.weight', 'backbone.bottom_up.stages.1.blocks.2.attn.proj.bias', 'backbone.bottom_up.stages.1.blocks.2.attn.sr.weight', 'backbone.bottom_up.stages.1.blocks.2.attn.sr.bias', 'backbone.bottom_up.stages.1.blocks.2.attn.norm.weight', 'backbone.bottom_up.stages.1.blocks.2.attn.norm.bias', 'backbone.bottom_up.stages.1.blocks.2.norm2.weight', 'backbone.bottom_up.stages.1.blocks.2.norm2.bias', 'backbone.bottom_up.stages.1.blocks.2.mlp.fc1.weight', 'backbone.bottom_up.stages.1.blocks.2.mlp.fc1.bias', 'backbone.bottom_up.stages.1.blocks.2.mlp.dwconv.weight', 'backbone.bottom_up.stages.1.blocks.2.mlp.dwconv.bias', 'backbone.bottom_up.stages.1.blocks.2.mlp.fc2.weight', 'backbone.bottom_up.stages.1.blocks.2.mlp.fc2.bias', 'backbone.bottom_up.stages.1.blocks.3.norm1.weight', 'backbone.bottom_up.stages.1.blocks.3.norm1.bias', 'backbone.bottom_up.stages.1.blocks.3.attn.q.weight', 'backbone.bottom_up.stages.1.blocks.3.attn.q.bias', 'backbone.bottom_up.stages.1.blocks.3.attn.kv.weight', 'backbone.bottom_up.stages.1.blocks.3.attn.kv.bias', 'backbone.bottom_up.stages.1.blocks.3.attn.proj.weight', 'backbone.bottom_up.stages.1.blocks.3.attn.proj.bias', 'backbone.bottom_up.stages.1.blocks.3.attn.sr.weight', 'backbone.bottom_up.stages.1.blocks.3.attn.sr.bias', 'backbone.bottom_up.stages.1.blocks.3.attn.norm.weight', 'backbone.bottom_up.stages.1.blocks.3.attn.norm.bias', 'backbone.bottom_up.stages.1.blocks.3.norm2.weight', 'backbone.bottom_up.stages.1.blocks.3.norm2.bias', 'backbone.bottom_up.stages.1.blocks.3.mlp.fc1.weight', 'backbone.bottom_up.stages.1.blocks.3.mlp.fc1.bias', 'backbone.bottom_up.stages.1.blocks.3.mlp.dwconv.weight', 'backbone.bottom_up.stages.1.blocks.3.mlp.dwconv.bias', 'backbone.bottom_up.stages.1.blocks.3.mlp.fc2.weight', 'backbone.bottom_up.stages.1.blocks.3.mlp.fc2.bias', 'backbone.bottom_up.stages.1.norm.weight', 'backbone.bottom_up.stages.1.norm.bias', 'backbone.bottom_up.stages.2.downsample.proj.weight', 'backbone.bottom_up.stages.2.downsample.proj.bias', 'backbone.bottom_up.stages.2.downsample.norm.weight', 'backbone.bottom_up.stages.2.downsample.norm.bias', 'backbone.bottom_up.stages.2.blocks.0.norm1.weight', 'backbone.bottom_up.stages.2.blocks.0.norm1.bias', 'backbone.bottom_up.stages.2.blocks.0.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.0.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.0.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.0.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.0.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.0.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.0.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.0.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.0.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.0.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.0.norm2.weight', 'backbone.bottom_up.stages.2.blocks.0.norm2.bias', 'backbone.bottom_up.stages.2.blocks.0.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.0.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.0.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.0.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.0.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.0.mlp.fc2.bias', 'backbone.bottom_up.stages.2.blocks.1.norm1.weight', 'backbone.bottom_up.stages.2.blocks.1.norm1.bias', 'backbone.bottom_up.stages.2.blocks.1.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.1.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.1.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.1.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.1.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.1.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.1.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.1.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.1.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.1.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.1.norm2.weight', 'backbone.bottom_up.stages.2.blocks.1.norm2.bias', 'backbone.bottom_up.stages.2.blocks.1.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.1.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.1.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.1.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.1.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.1.mlp.fc2.bias', 'backbone.bottom_up.stages.2.blocks.2.norm1.weight', 'backbone.bottom_up.stages.2.blocks.2.norm1.bias', 'backbone.bottom_up.stages.2.blocks.2.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.2.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.2.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.2.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.2.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.2.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.2.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.2.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.2.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.2.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.2.norm2.weight', 'backbone.bottom_up.stages.2.blocks.2.norm2.bias', 'backbone.bottom_up.stages.2.blocks.2.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.2.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.2.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.2.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.2.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.2.mlp.fc2.bias', 'backbone.bottom_up.stages.2.blocks.3.norm1.weight', 'backbone.bottom_up.stages.2.blocks.3.norm1.bias', 'backbone.bottom_up.stages.2.blocks.3.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.3.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.3.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.3.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.3.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.3.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.3.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.3.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.3.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.3.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.3.norm2.weight', 'backbone.bottom_up.stages.2.blocks.3.norm2.bias', 'backbone.bottom_up.stages.2.blocks.3.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.3.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.3.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.3.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.3.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.3.mlp.fc2.bias', 'backbone.bottom_up.stages.2.blocks.4.norm1.weight', 'backbone.bottom_up.stages.2.blocks.4.norm1.bias', 'backbone.bottom_up.stages.2.blocks.4.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.4.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.4.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.4.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.4.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.4.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.4.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.4.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.4.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.4.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.4.norm2.weight', 'backbone.bottom_up.stages.2.blocks.4.norm2.bias', 'backbone.bottom_up.stages.2.blocks.4.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.4.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.4.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.4.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.4.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.4.mlp.fc2.bias', 'backbone.bottom_up.stages.2.blocks.5.norm1.weight', 'backbone.bottom_up.stages.2.blocks.5.norm1.bias', 'backbone.bottom_up.stages.2.blocks.5.attn.q.weight', 'backbone.bottom_up.stages.2.blocks.5.attn.q.bias', 'backbone.bottom_up.stages.2.blocks.5.attn.kv.weight', 'backbone.bottom_up.stages.2.blocks.5.attn.kv.bias', 'backbone.bottom_up.stages.2.blocks.5.attn.proj.weight', 'backbone.bottom_up.stages.2.blocks.5.attn.proj.bias', 'backbone.bottom_up.stages.2.blocks.5.attn.sr.weight', 'backbone.bottom_up.stages.2.blocks.5.attn.sr.bias', 'backbone.bottom_up.stages.2.blocks.5.attn.norm.weight', 'backbone.bottom_up.stages.2.blocks.5.attn.norm.bias', 'backbone.bottom_up.stages.2.blocks.5.norm2.weight', 'backbone.bottom_up.stages.2.blocks.5.norm2.bias', 'backbone.bottom_up.stages.2.blocks.5.mlp.fc1.weight', 'backbone.bottom_up.stages.2.blocks.5.mlp.fc1.bias', 'backbone.bottom_up.stages.2.blocks.5.mlp.dwconv.weight', 'backbone.bottom_up.stages.2.blocks.5.mlp.dwconv.bias', 'backbone.bottom_up.stages.2.blocks.5.mlp.fc2.weight', 'backbone.bottom_up.stages.2.blocks.5.mlp.fc2.bias', 'backbone.bottom_up.stages.2.norm.weight', 'backbone.bottom_up.stages.2.norm.bias', 'proposal_generator.rpn_head.conv.weight', 'proposal_generator.rpn_head.conv.bias', 'proposal_generator.rpn_head.objectness_logits.weight', 'proposal_generator.rpn_head.objectness_logits.bias', 'proposal_generator.rpn_head.anchor_deltas.weight', 'proposal_generator.rpn_head.anchor_deltas.bias', 'roi_heads.box_head.stage.downsample.proj.weight', 'roi_heads.box_head.stage.downsample.proj.bias', 'roi_heads.box_head.stage.downsample.norm.weight', 'roi_heads.box_head.stage.downsample.norm.bias', 'roi_heads.box_head.stage.blocks.0.norm1.weight', 'roi_heads.box_head.stage.blocks.0.norm1.bias', 'roi_heads.box_head.stage.blocks.0.attn.q.weight', 'roi_heads.box_head.stage.blocks.0.attn.q.bias', 'roi_heads.box_head.stage.blocks.0.attn.kv.weight', 'roi_heads.box_head.stage.blocks.0.attn.kv.bias', 'roi_heads.box_head.stage.blocks.0.attn.proj.weight', 'roi_heads.box_head.stage.blocks.0.attn.proj.bias', 'roi_heads.box_head.stage.blocks.0.attn.sr.weight', 'roi_heads.box_head.stage.blocks.0.attn.sr.bias', 'roi_heads.box_head.stage.blocks.0.attn.norm.weight', 'roi_heads.box_head.stage.blocks.0.attn.norm.bias', 'roi_heads.box_head.stage.blocks.0.norm2.weight', 'roi_heads.box_head.stage.blocks.0.norm2.bias', 'roi_heads.box_head.stage.blocks.0.mlp.fc1.weight', 'roi_heads.box_head.stage.blocks.0.mlp.fc1.bias', 'roi_heads.box_head.stage.blocks.0.mlp.dwconv.weight', 'roi_heads.box_head.stage.blocks.0.mlp.dwconv.bias', 'roi_heads.box_head.stage.blocks.0.mlp.fc2.weight', 'roi_heads.box_head.stage.blocks.0.mlp.fc2.bias', 'roi_heads.box_head.stage.blocks.1.norm1.weight', 'roi_heads.box_head.stage.blocks.1.norm1.bias', 'roi_heads.box_head.stage.blocks.1.attn.q.weight', 'roi_heads.box_head.stage.blocks.1.attn.q.bias', 'roi_heads.box_head.stage.blocks.1.attn.kv.weight', 'roi_heads.box_head.stage.blocks.1.attn.kv.bias', 'roi_heads.box_head.stage.blocks.1.attn.proj.weight', 'roi_heads.box_head.stage.blocks.1.attn.proj.bias', 'roi_heads.box_head.stage.blocks.1.attn.sr.weight', 'roi_heads.box_head.stage.blocks.1.attn.sr.bias', 'roi_heads.box_head.stage.blocks.1.attn.norm.weight', 'roi_heads.box_head.stage.blocks.1.attn.norm.bias', 'roi_heads.box_head.stage.blocks.1.norm2.weight', 'roi_heads.box_head.stage.blocks.1.norm2.bias', 'roi_heads.box_head.stage.blocks.1.mlp.fc1.weight', 'roi_heads.box_head.stage.blocks.1.mlp.fc1.bias', 'roi_heads.box_head.stage.blocks.1.mlp.dwconv.weight', 'roi_heads.box_head.stage.blocks.1.mlp.dwconv.bias', 'roi_heads.box_head.stage.blocks.1.mlp.fc2.weight', 'roi_heads.box_head.stage.blocks.1.mlp.fc2.bias', 'roi_heads.box_head.stage.blocks.2.norm1.weight', 'roi_heads.box_head.stage.blocks.2.norm1.bias', 'roi_heads.box_head.stage.blocks.2.attn.q.weight', 'roi_heads.box_head.stage.blocks.2.attn.q.bias', 'roi_heads.box_head.stage.blocks.2.attn.kv.weight', 'roi_heads.box_head.stage.blocks.2.attn.kv.bias', 'roi_heads.box_head.stage.blocks.2.attn.proj.weight', 'roi_heads.box_head.stage.blocks.2.attn.proj.bias', 'roi_heads.box_head.stage.blocks.2.attn.sr.weight', 'roi_heads.box_head.stage.blocks.2.attn.sr.bias', 'roi_heads.box_head.stage.blocks.2.attn.norm.weight', 'roi_heads.box_head.stage.blocks.2.attn.norm.bias', 'roi_heads.box_head.stage.blocks.2.norm2.weight', 'roi_heads.box_head.stage.blocks.2.norm2.bias', 'roi_heads.box_head.stage.blocks.2.mlp.fc1.weight', 'roi_heads.box_head.stage.blocks.2.mlp.fc1.bias', 'roi_heads.box_head.stage.blocks.2.mlp.dwconv.weight', 'roi_heads.box_head.stage.blocks.2.mlp.dwconv.bias', 'roi_heads.box_head.stage.blocks.2.mlp.fc2.weight', 'roi_heads.box_head.stage.blocks.2.mlp.fc2.bias', 'roi_heads.box_head.stage.norm.weight', 'roi_heads.box_head.stage.norm.bias', 'roi_heads.box_predictor.cls_score.weight', 'roi_heads.box_predictor.cls_score.bias', 'roi_heads.box_predictor.bbox_pred.weight', 'roi_heads.box_predictor.bbox_pred.bias']
============ using the AdamW optimizer for all the parameters ============
[06/18 16:02:10 d2.data.datasets.coco]: Loading ./datasets/data/dota_dataset/coco/new_annotations/final_split_non_voc_instances_train2014_with_small.json takes 3.87 seconds.
[06/18 16:02:11 d2.data.datasets.coco]: Loaded 54087 images in COCO format from ./datasets/data/dota_dataset/coco/new_annotations/final_split_non_voc_instances_train2014_with_small.json
[06/18 16:02:13 d2.data.build]: Removed 3214 images with no usable annotations. 50873 images left.
[06/18 16:02:14 d2.data.build]: Distribution of instances among all 16 categories:
|   category    | #instances   |   category    | #instances   |   category    | #instances   |
|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|
|     plane     | 30326        |     ship      | 126863       | storage-tank  | 0            |
| baseball-di.. | 1493         | tennis-court  | 0            | basketball-.. | 1958         |
| ground-trac.. | 1074         |    harbor     | 22506        |    bridge     | 7456         |
| small-vehicle | 441058       | large-vehicle | 83431        |  roundabout   | 1586         |
| swimming-pool | 7899         |  helicopter   | 2399         | soccer-ball.. | 0            |
| container-c.. | 558          |               |              |               |              |
|     total     | 728607       |               |              |               |              |
[06/18 16:02:14 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[06/18 16:02:14 d2.data.build]: Using training sampler TrainingSampler
[06/18 16:02:14 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/18 16:02:14 d2.data.common]: Serializing 50873 elements to byte tensors and concatenating them all ...
[06/18 16:02:14 d2.data.common]: Serialized dataset takes 113.03 MiB
[06/18 16:02:14 d2.data.build]: Making batched data loader with batch_size=1
[06/18 16:02:15 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./weights/pvt_v2_b2_li.pth ...
[06/18 16:02:15 fvcore.common.checkpoint]: [Checkpointer] Loading from ./weights/pvt_v2_b2_li.pth ...
WARNING [06/18 16:02:15 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
backbone.bottom_up.patch_embed.norm.{bias, weight}
backbone.bottom_up.patch_embed.proj.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.attn.kv.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.attn.norm.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.attn.proj.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.attn.q.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.attn.sr.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.norm1.{bias, weight}
backbone.bottom_up.stages.0.blocks.0.norm2.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.attn.kv.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.attn.norm.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.attn.proj.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.attn.q.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.attn.sr.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.norm1.{bias, weight}
backbone.bottom_up.stages.0.blocks.1.norm2.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.attn.kv.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.attn.norm.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.attn.proj.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.attn.q.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.attn.sr.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.norm1.{bias, weight}
backbone.bottom_up.stages.0.blocks.2.norm2.{bias, weight}
backbone.bottom_up.stages.0.norm.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.attn.kv.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.attn.norm.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.attn.proj.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.attn.q.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.attn.sr.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.norm1.{bias, weight}
backbone.bottom_up.stages.1.blocks.0.norm2.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.attn.kv.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.attn.norm.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.attn.proj.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.attn.q.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.attn.sr.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.norm1.{bias, weight}
backbone.bottom_up.stages.1.blocks.1.norm2.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.attn.kv.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.attn.norm.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.attn.proj.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.attn.q.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.attn.sr.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.norm1.{bias, weight}
backbone.bottom_up.stages.1.blocks.2.norm2.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.attn.kv.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.attn.norm.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.attn.proj.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.attn.q.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.attn.sr.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.norm1.{bias, weight}
backbone.bottom_up.stages.1.blocks.3.norm2.{bias, weight}
backbone.bottom_up.stages.1.downsample.norm.{bias, weight}
backbone.bottom_up.stages.1.downsample.proj.{bias, weight}
backbone.bottom_up.stages.1.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.0.norm2.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.1.norm2.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.2.norm2.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.3.norm2.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.4.norm2.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.attn.kv.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.attn.norm.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.attn.proj.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.attn.q.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.attn.sr.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.mlp.dwconv.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.mlp.fc1.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.mlp.fc2.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.norm1.{bias, weight}
backbone.bottom_up.stages.2.blocks.5.norm2.{bias, weight}
backbone.bottom_up.stages.2.downsample.norm.{bias, weight}
backbone.bottom_up.stages.2.downsample.proj.{bias, weight}
backbone.bottom_up.stages.2.norm.{bias, weight}
backbone.fpn_lateral3.{bias, weight}
backbone.fpn_lateral4.{bias, weight}
backbone.fpn_output3.{bias, weight}
backbone.fpn_output4.{bias, weight}
backbone.top_block.p6.{bias, weight}
backbone.top_block.p7.{bias, weight}
proposal_generator.rpn_head.anchor_deltas.{bias, weight}
proposal_generator.rpn_head.conv.{bias, weight}
proposal_generator.rpn_head.objectness_logits.{bias, weight}
roi_heads.box_head.stage.blocks.0.attn.kv.{bias, weight}
roi_heads.box_head.stage.blocks.0.attn.norm.{bias, weight}
roi_heads.box_head.stage.blocks.0.attn.proj.{bias, weight}
roi_heads.box_head.stage.blocks.0.attn.q.{bias, weight}
roi_heads.box_head.stage.blocks.0.attn.sr.{bias, weight}
roi_heads.box_head.stage.blocks.0.mlp.dwconv.{bias, weight}
roi_heads.box_head.stage.blocks.0.mlp.fc1.{bias, weight}
roi_heads.box_head.stage.blocks.0.mlp.fc2.{bias, weight}
roi_heads.box_head.stage.blocks.0.norm1.{bias, weight}
roi_heads.box_head.stage.blocks.0.norm2.{bias, weight}
roi_heads.box_head.stage.blocks.1.attn.kv.{bias, weight}
roi_heads.box_head.stage.blocks.1.attn.norm.{bias, weight}
roi_heads.box_head.stage.blocks.1.attn.proj.{bias, weight}
roi_heads.box_head.stage.blocks.1.attn.q.{bias, weight}
roi_heads.box_head.stage.blocks.1.attn.sr.{bias, weight}
roi_heads.box_head.stage.blocks.1.mlp.dwconv.{bias, weight}
roi_heads.box_head.stage.blocks.1.mlp.fc1.{bias, weight}
roi_heads.box_head.stage.blocks.1.mlp.fc2.{bias, weight}
roi_heads.box_head.stage.blocks.1.norm1.{bias, weight}
roi_heads.box_head.stage.blocks.1.norm2.{bias, weight}
roi_heads.box_head.stage.blocks.2.attn.kv.{bias, weight}
roi_heads.box_head.stage.blocks.2.attn.norm.{bias, weight}
roi_heads.box_head.stage.blocks.2.attn.proj.{bias, weight}
roi_heads.box_head.stage.blocks.2.attn.q.{bias, weight}
roi_heads.box_head.stage.blocks.2.attn.sr.{bias, weight}
roi_heads.box_head.stage.blocks.2.mlp.dwconv.{bias, weight}
roi_heads.box_head.stage.blocks.2.mlp.fc1.{bias, weight}
roi_heads.box_head.stage.blocks.2.mlp.fc2.{bias, weight}
roi_heads.box_head.stage.blocks.2.norm1.{bias, weight}
roi_heads.box_head.stage.blocks.2.norm2.{bias, weight}
roi_heads.box_head.stage.downsample.norm.{bias, weight}
roi_heads.box_head.stage.downsample.proj.{bias, weight}
roi_heads.box_head.stage.norm.{bias, weight}
roi_heads.box_predictor.bbox_pred.{bias, weight}
roi_heads.box_predictor.cls_score.{bias, weight}
WARNING [06/18 16:02:15 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  patch_embed.proj.{bias, weight}
  patch_embed.norm.{bias, weight}
  stages.0.blocks.0.norm1.{bias, weight}
  stages.0.blocks.0.attn.q.{bias, weight}
  stages.0.blocks.0.attn.kv.{bias, weight}
  stages.0.blocks.0.attn.proj.{bias, weight}
  stages.0.blocks.0.attn.sr.{bias, weight}
  stages.0.blocks.0.attn.norm.{bias, weight}
  stages.0.blocks.0.norm2.{bias, weight}
  stages.0.blocks.0.mlp.fc1.{bias, weight}
  stages.0.blocks.0.mlp.dwconv.{bias, weight}
  stages.0.blocks.0.mlp.fc2.{bias, weight}
  stages.0.blocks.1.norm1.{bias, weight}
  stages.0.blocks.1.attn.q.{bias, weight}
  stages.0.blocks.1.attn.kv.{bias, weight}
  stages.0.blocks.1.attn.proj.{bias, weight}
  stages.0.blocks.1.attn.sr.{bias, weight}
  stages.0.blocks.1.attn.norm.{bias, weight}
  stages.0.blocks.1.norm2.{bias, weight}
  stages.0.blocks.1.mlp.fc1.{bias, weight}
  stages.0.blocks.1.mlp.dwconv.{bias, weight}
  stages.0.blocks.1.mlp.fc2.{bias, weight}
  stages.0.blocks.2.norm1.{bias, weight}
  stages.0.blocks.2.attn.q.{bias, weight}
  stages.0.blocks.2.attn.kv.{bias, weight}
  stages.0.blocks.2.attn.proj.{bias, weight}
  stages.0.blocks.2.attn.sr.{bias, weight}
  stages.0.blocks.2.attn.norm.{bias, weight}
  stages.0.blocks.2.norm2.{bias, weight}
  stages.0.blocks.2.mlp.fc1.{bias, weight}
  stages.0.blocks.2.mlp.dwconv.{bias, weight}
  stages.0.blocks.2.mlp.fc2.{bias, weight}
  stages.0.norm.{bias, weight}
  stages.1.downsample.proj.{bias, weight}
  stages.1.downsample.norm.{bias, weight}
  stages.1.blocks.0.norm1.{bias, weight}
  stages.1.blocks.0.attn.q.{bias, weight}
  stages.1.blocks.0.attn.kv.{bias, weight}
  stages.1.blocks.0.attn.proj.{bias, weight}
  stages.1.blocks.0.attn.sr.{bias, weight}
  stages.1.blocks.0.attn.norm.{bias, weight}
  stages.1.blocks.0.norm2.{bias, weight}
  stages.1.blocks.0.mlp.fc1.{bias, weight}
  stages.1.blocks.0.mlp.dwconv.{bias, weight}
  stages.1.blocks.0.mlp.fc2.{bias, weight}
  stages.1.blocks.1.norm1.{bias, weight}
  stages.1.blocks.1.attn.q.{bias, weight}
  stages.1.blocks.1.attn.kv.{bias, weight}
  stages.1.blocks.1.attn.proj.{bias, weight}
  stages.1.blocks.1.attn.sr.{bias, weight}
  stages.1.blocks.1.attn.norm.{bias, weight}
  stages.1.blocks.1.norm2.{bias, weight}
  stages.1.blocks.1.mlp.fc1.{bias, weight}
  stages.1.blocks.1.mlp.dwconv.{bias, weight}
  stages.1.blocks.1.mlp.fc2.{bias, weight}
  stages.1.blocks.2.norm1.{bias, weight}
  stages.1.blocks.2.attn.q.{bias, weight}
  stages.1.blocks.2.attn.kv.{bias, weight}
  stages.1.blocks.2.attn.proj.{bias, weight}
  stages.1.blocks.2.attn.sr.{bias, weight}
  stages.1.blocks.2.attn.norm.{bias, weight}
  stages.1.blocks.2.norm2.{bias, weight}
  stages.1.blocks.2.mlp.fc1.{bias, weight}
  stages.1.blocks.2.mlp.dwconv.{bias, weight}
  stages.1.blocks.2.mlp.fc2.{bias, weight}
  stages.1.blocks.3.norm1.{bias, weight}
  stages.1.blocks.3.attn.q.{bias, weight}
  stages.1.blocks.3.attn.kv.{bias, weight}
  stages.1.blocks.3.attn.proj.{bias, weight}
  stages.1.blocks.3.attn.sr.{bias, weight}
  stages.1.blocks.3.attn.norm.{bias, weight}
  stages.1.blocks.3.norm2.{bias, weight}
  stages.1.blocks.3.mlp.fc1.{bias, weight}
  stages.1.blocks.3.mlp.dwconv.{bias, weight}
  stages.1.blocks.3.mlp.fc2.{bias, weight}
  stages.1.norm.{bias, weight}
  stages.2.downsample.proj.{bias, weight}
  stages.2.downsample.norm.{bias, weight}
  stages.2.blocks.0.norm1.{bias, weight}
  stages.2.blocks.0.attn.q.{bias, weight}
  stages.2.blocks.0.attn.kv.{bias, weight}
  stages.2.blocks.0.attn.proj.{bias, weight}
  stages.2.blocks.0.attn.sr.{bias, weight}
  stages.2.blocks.0.attn.norm.{bias, weight}
  stages.2.blocks.0.norm2.{bias, weight}
  stages.2.blocks.0.mlp.fc1.{bias, weight}
  stages.2.blocks.0.mlp.dwconv.{bias, weight}
  stages.2.blocks.0.mlp.fc2.{bias, weight}
  stages.2.blocks.1.norm1.{bias, weight}
  stages.2.blocks.1.attn.q.{bias, weight}
  stages.2.blocks.1.attn.kv.{bias, weight}
  stages.2.blocks.1.attn.proj.{bias, weight}
  stages.2.blocks.1.attn.sr.{bias, weight}
  stages.2.blocks.1.attn.norm.{bias, weight}
  stages.2.blocks.1.norm2.{bias, weight}
  stages.2.blocks.1.mlp.fc1.{bias, weight}
  stages.2.blocks.1.mlp.dwconv.{bias, weight}
  stages.2.blocks.1.mlp.fc2.{bias, weight}
  stages.2.blocks.2.norm1.{bias, weight}
  stages.2.blocks.2.attn.q.{bias, weight}
  stages.2.blocks.2.attn.kv.{bias, weight}
  stages.2.blocks.2.attn.proj.{bias, weight}
  stages.2.blocks.2.attn.sr.{bias, weight}
  stages.2.blocks.2.attn.norm.{bias, weight}
  stages.2.blocks.2.norm2.{bias, weight}
  stages.2.blocks.2.mlp.fc1.{bias, weight}
  stages.2.blocks.2.mlp.dwconv.{bias, weight}
  stages.2.blocks.2.mlp.fc2.{bias, weight}
  stages.2.blocks.3.norm1.{bias, weight}
  stages.2.blocks.3.attn.q.{bias, weight}
  stages.2.blocks.3.attn.kv.{bias, weight}
  stages.2.blocks.3.attn.proj.{bias, weight}
  stages.2.blocks.3.attn.sr.{bias, weight}
  stages.2.blocks.3.attn.norm.{bias, weight}
  stages.2.blocks.3.norm2.{bias, weight}
  stages.2.blocks.3.mlp.fc1.{bias, weight}
  stages.2.blocks.3.mlp.dwconv.{bias, weight}
  stages.2.blocks.3.mlp.fc2.{bias, weight}
  stages.2.blocks.4.norm1.{bias, weight}
  stages.2.blocks.4.attn.q.{bias, weight}
  stages.2.blocks.4.attn.kv.{bias, weight}
  stages.2.blocks.4.attn.proj.{bias, weight}
  stages.2.blocks.4.attn.sr.{bias, weight}
  stages.2.blocks.4.attn.norm.{bias, weight}
  stages.2.blocks.4.norm2.{bias, weight}
  stages.2.blocks.4.mlp.fc1.{bias, weight}
  stages.2.blocks.4.mlp.dwconv.{bias, weight}
  stages.2.blocks.4.mlp.fc2.{bias, weight}
  stages.2.blocks.5.norm1.{bias, weight}
  stages.2.blocks.5.attn.q.{bias, weight}
  stages.2.blocks.5.attn.kv.{bias, weight}
  stages.2.blocks.5.attn.proj.{bias, weight}
  stages.2.blocks.5.attn.sr.{bias, weight}
  stages.2.blocks.5.attn.norm.{bias, weight}
  stages.2.blocks.5.norm2.{bias, weight}
  stages.2.blocks.5.mlp.fc1.{bias, weight}
  stages.2.blocks.5.mlp.dwconv.{bias, weight}
  stages.2.blocks.5.mlp.fc2.{bias, weight}
  stages.2.norm.{bias, weight}
  stages.3.downsample.proj.{bias, weight}
  stages.3.downsample.norm.{bias, weight}
  stages.3.blocks.0.norm1.{bias, weight}
  stages.3.blocks.0.attn.q.{bias, weight}
  stages.3.blocks.0.attn.kv.{bias, weight}
  stages.3.blocks.0.attn.proj.{bias, weight}
  stages.3.blocks.0.attn.sr.{bias, weight}
  stages.3.blocks.0.attn.norm.{bias, weight}
  stages.3.blocks.0.norm2.{bias, weight}
  stages.3.blocks.0.mlp.fc1.{bias, weight}
  stages.3.blocks.0.mlp.dwconv.{bias, weight}
  stages.3.blocks.0.mlp.fc2.{bias, weight}
  stages.3.blocks.1.norm1.{bias, weight}
  stages.3.blocks.1.attn.q.{bias, weight}
  stages.3.blocks.1.attn.kv.{bias, weight}
  stages.3.blocks.1.attn.proj.{bias, weight}
  stages.3.blocks.1.attn.sr.{bias, weight}
  stages.3.blocks.1.attn.norm.{bias, weight}
  stages.3.blocks.1.norm2.{bias, weight}
  stages.3.blocks.1.mlp.fc1.{bias, weight}
  stages.3.blocks.1.mlp.dwconv.{bias, weight}
  stages.3.blocks.1.mlp.fc2.{bias, weight}
  stages.3.blocks.2.norm1.{bias, weight}
  stages.3.blocks.2.attn.q.{bias, weight}
  stages.3.blocks.2.attn.kv.{bias, weight}
  stages.3.blocks.2.attn.proj.{bias, weight}
  stages.3.blocks.2.attn.sr.{bias, weight}
  stages.3.blocks.2.attn.norm.{bias, weight}
  stages.3.blocks.2.norm2.{bias, weight}
  stages.3.blocks.2.mlp.fc1.{bias, weight}
  stages.3.blocks.2.mlp.dwconv.{bias, weight}
  stages.3.blocks.2.mlp.fc2.{bias, weight}
  stages.3.norm.{bias, weight}
  head.{bias, weight}
[06/18 16:02:15 d2.engine.train_loop]: Starting training from iteration 0
/home/gonem/.conda/envs/fct/lib/python3.11/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
[06/18 16:02:21 d2.utils.events]:  eta: 8:32:57  iter: 19  total_loss: 3.408  loss_cls: 2.276  loss_box_reg: 0.05136  loss_rpn_cls: 0.6984  loss_rpn_loc: 0.02582    time: 0.2910  last_time: 0.2673  data_time: 0.0073  last_data_time: 0.0017   lr: 3.9962e-06  max_mem: 6696M
[06/18 16:02:27 d2.utils.events]:  eta: 8:36:24  iter: 39  total_loss: 2.097  loss_cls: 1.11  loss_box_reg: 0.05019  loss_rpn_cls: 0.6967  loss_rpn_loc: 0.01559    time: 0.2873  last_time: 0.3139  data_time: 0.0015  last_data_time: 0.0013   lr: 7.9922e-06  max_mem: 6696M
[06/18 16:02:33 d2.utils.events]:  eta: 8:35:36  iter: 59  total_loss: 1.047  loss_cls: 0.2694  loss_box_reg: 0.02929  loss_rpn_cls: 0.6965  loss_rpn_loc: 0.01516    time: 0.2862  last_time: 0.2764  data_time: 0.0015  last_data_time: 0.0019   lr: 1.1988e-05  max_mem: 6696M
[06/18 16:02:38 d2.utils.events]:  eta: 8:35:30  iter: 79  total_loss: 1.064  loss_cls: 0.2716  loss_box_reg: 0.05538  loss_rpn_cls: 0.6927  loss_rpn_loc: 0.04185    time: 0.2854  last_time: 0.2943  data_time: 0.0015  last_data_time: 0.0014   lr: 1.5984e-05  max_mem: 6696M
[06/18 16:02:44 d2.utils.events]:  eta: 8:36:36  iter: 99  total_loss: 1.547  loss_cls: 0.6537  loss_box_reg: 0.1242  loss_rpn_cls: 0.6898  loss_rpn_loc: 0.03763    time: 0.2852  last_time: 0.2730  data_time: 0.0015  last_data_time: 0.0013   lr: 1.998e-05  max_mem: 6696M
[06/18 16:02:50 d2.utils.events]:  eta: 8:37:53  iter: 119  total_loss: 0.8597  loss_cls: 0.1433  loss_box_reg: 0.02366  loss_rpn_cls: 0.6824  loss_rpn_loc: 0.01169    time: 0.2859  last_time: 0.2998  data_time: 0.0015  last_data_time: 0.0016   lr: 2.3976e-05  max_mem: 6696M
[06/18 16:02:55 d2.utils.events]:  eta: 8:37:35  iter: 139  total_loss: 1.02  loss_cls: 0.27  loss_box_reg: 0.04436  loss_rpn_cls: 0.6802  loss_rpn_loc: 0.0328    time: 0.2855  last_time: 0.2822  data_time: 0.0016  last_data_time: 0.0015   lr: 2.7972e-05  max_mem: 6696M
[06/18 16:03:01 d2.utils.events]:  eta: 8:37:29  iter: 159  total_loss: 1.162  loss_cls: 0.3074  loss_box_reg: 0.07148  loss_rpn_cls: 0.6728  loss_rpn_loc: 0.03382    time: 0.2856  last_time: 0.3079  data_time: 0.0016  last_data_time: 0.0014   lr: 3.1968e-05  max_mem: 6696M
[06/18 16:03:07 d2.utils.events]:  eta: 8:37:28  iter: 179  total_loss: 1.245  loss_cls: 0.3972  loss_box_reg: 0.05062  loss_rpn_cls: 0.6659  loss_rpn_loc: 0.02064    time: 0.2855  last_time: 0.2686  data_time: 0.0016  last_data_time: 0.0014   lr: 3.5964e-05  max_mem: 6696M
[06/18 16:03:13 d2.utils.events]:  eta: 8:37:18  iter: 199  total_loss: 0.8058  loss_cls: 0.1025  loss_box_reg: 0.02177  loss_rpn_cls: 0.6489  loss_rpn_loc: 0.01792    time: 0.2855  last_time: 0.3186  data_time: 0.0014  last_data_time: 0.0012   lr: 3.996e-05  max_mem: 6696M
[06/18 16:03:18 d2.utils.events]:  eta: 8:37:05  iter: 219  total_loss: 0.7269  loss_cls: 0.06943  loss_box_reg: 0.02915  loss_rpn_cls: 0.6344  loss_rpn_loc: 0.01501    time: 0.2855  last_time: 0.2943  data_time: 0.0015  last_data_time: 0.0016   lr: 4.3956e-05  max_mem: 6696M
[06/18 16:03:24 d2.utils.events]:  eta: 8:37:07  iter: 239  total_loss: 1.042  loss_cls: 0.2608  loss_box_reg: 0.1233  loss_rpn_cls: 0.6218  loss_rpn_loc: 0.02539    time: 0.2857  last_time: 0.3213  data_time: 0.0015  last_data_time: 0.0014   lr: 4.7952e-05  max_mem: 6696M
[06/18 16:03:30 d2.utils.events]:  eta: 8:36:46  iter: 259  total_loss: 0.935  loss_cls: 0.2109  loss_box_reg: 0.04314  loss_rpn_cls: 0.6158  loss_rpn_loc: 0.04275    time: 0.2853  last_time: 0.2833  data_time: 0.0015  last_data_time: 0.0017   lr: 5.1948e-05  max_mem: 6696M
[06/18 16:03:35 d2.utils.events]:  eta: 8:36:41  iter: 279  total_loss: 0.7923  loss_cls: 0.175  loss_box_reg: 0.04068  loss_rpn_cls: 0.5575  loss_rpn_loc: 0.0166    time: 0.2853  last_time: 0.2951  data_time: 0.0015  last_data_time: 0.0016   lr: 5.5944e-05  max_mem: 6696M
[06/18 16:03:41 d2.utils.events]:  eta: 8:36:42  iter: 299  total_loss: 0.7585  loss_cls: 0.1417  loss_box_reg: 0.03852  loss_rpn_cls: 0.5385  loss_rpn_loc: 0.009176    time: 0.2853  last_time: 0.2822  data_time: 0.0016  last_data_time: 0.0016   lr: 5.994e-05  max_mem: 6696M
[06/18 16:03:47 d2.utils.events]:  eta: 8:36:44  iter: 319  total_loss: 0.5995  loss_cls: 0.07901  loss_box_reg: 0.01134  loss_rpn_cls: 0.5047  loss_rpn_loc: 0.01303    time: 0.2853  last_time: 0.2948  data_time: 0.0014  last_data_time: 0.0014   lr: 6.3936e-05  max_mem: 6696M
[06/18 16:03:53 d2.utils.events]:  eta: 8:36:44  iter: 339  total_loss: 0.5848  loss_cls: 0.1048  loss_box_reg: 0.04751  loss_rpn_cls: 0.4259  loss_rpn_loc: 0.01746    time: 0.2853  last_time: 0.2698  data_time: 0.0013  last_data_time: 0.0013   lr: 6.7932e-05  max_mem: 6696M
[06/18 16:03:58 d2.utils.events]:  eta: 8:36:26  iter: 359  total_loss: 0.5893  loss_cls: 0.1468  loss_box_reg: 0.06494  loss_rpn_cls: 0.3796  loss_rpn_loc: 0.0261    time: 0.2851  last_time: 0.2953  data_time: 0.0013  last_data_time: 0.0012   lr: 7.1928e-05  max_mem: 6696M
[06/18 16:04:04 d2.utils.events]:  eta: 8:36:20  iter: 379  total_loss: 0.4645  loss_cls: 0.08409  loss_box_reg: 0.04029  loss_rpn_cls: 0.2938  loss_rpn_loc: 0.023    time: 0.2850  last_time: 0.2893  data_time: 0.0013  last_data_time: 0.0014   lr: 7.5924e-05  max_mem: 6696M
[06/18 16:04:10 d2.utils.events]:  eta: 8:36:22  iter: 399  total_loss: 0.5855  loss_cls: 0.1527  loss_box_reg: 0.07014  loss_rpn_cls: 0.2678  loss_rpn_loc: 0.03892    time: 0.2850  last_time: 0.3198  data_time: 0.0013  last_data_time: 0.0014   lr: 7.992e-05  max_mem: 6696M
[06/18 16:04:15 d2.utils.events]:  eta: 8:36:24  iter: 419  total_loss: 0.3538  loss_cls: 0.1268  loss_box_reg: 0.03417  loss_rpn_cls: 0.2538  loss_rpn_loc: 0.0177    time: 0.2850  last_time: 0.2782  data_time: 0.0013  last_data_time: 0.0013   lr: 8.3916e-05  max_mem: 6696M
[06/18 16:04:21 d2.utils.events]:  eta: 8:36:16  iter: 439  total_loss: 0.7069  loss_cls: 0.2543  loss_box_reg: 0.06671  loss_rpn_cls: 0.2473  loss_rpn_loc: 0.05658    time: 0.2850  last_time: 0.3223  data_time: 0.0013  last_data_time: 0.0016   lr: 8.7912e-05  max_mem: 6696M
[06/18 16:04:27 d2.utils.events]:  eta: 8:36:12  iter: 459  total_loss: 0.3808  loss_cls: 0.09694  loss_box_reg: 0.04607  loss_rpn_cls: 0.2034  loss_rpn_loc: 0.02828    time: 0.2851  last_time: 0.2822  data_time: 0.0015  last_data_time: 0.0014   lr: 9.1908e-05  max_mem: 6696M
[06/18 16:04:33 d2.utils.events]:  eta: 8:36:09  iter: 479  total_loss: 0.6006  loss_cls: 0.1983  loss_box_reg: 0.1022  loss_rpn_cls: 0.2284  loss_rpn_loc: 0.06345    time: 0.2853  last_time: 0.3004  data_time: 0.0014  last_data_time: 0.0014   lr: 9.5904e-05  max_mem: 6696M
[06/18 16:04:38 d2.utils.events]:  eta: 8:36:10  iter: 499  total_loss: 0.5047  loss_cls: 0.1674  loss_box_reg: 0.1053  loss_rpn_cls: 0.1383  loss_rpn_loc: 0.02179    time: 0.2853  last_time: 0.2946  data_time: 0.0014  last_data_time: 0.0014   lr: 9.99e-05  max_mem: 6696M
[06/18 16:04:44 d2.utils.events]:  eta: 8:36:12  iter: 519  total_loss: 0.4814  loss_cls: 0.1637  loss_box_reg: 0.08658  loss_rpn_cls: 0.2415  loss_rpn_loc: 0.02894    time: 0.2852  last_time: 0.3001  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0001039  max_mem: 6696M
